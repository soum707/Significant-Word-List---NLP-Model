{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895d47f7",
   "metadata": {},
   "source": [
    "Tasks: <br>\n",
    "<br>\n",
    "1- get the full lemmatized word list <br>\n",
    "2- get the 95% coverage word list <br>\n",
    "3- remove stop words from 95% swl <br>\n",
    "4- compare ngsl coverage on full lemmatized word list\n",
    "\n",
    "- make 95% default and changable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a80597",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da386979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/soum/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/soum/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/soum/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/soum/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/soum/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a30fad88d049ac9a62b7a8785dbaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 18:32:09 INFO: Downloaded file to /Users/soum/stanza_resources/resources.json\n",
      "2025-04-25 18:32:09 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-04-25 18:32:11 INFO: File exists: /Users/soum/stanza_resources/en/default.zip\n",
      "2025-04-25 18:32:14 INFO: Finished downloading models and saved to /Users/soum/stanza_resources\n",
      "2025-04-25 18:32:14 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dbadc7f1b04703aa11bd3f7c08c74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 18:32:14 INFO: Downloaded file to /Users/soum/stanza_resources/resources.json\n",
      "2025-04-25 18:32:14 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-04-25 18:32:15 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2025-04-25 18:32:15 INFO: Using device: cpu\n",
      "2025-04-25 18:32:15 INFO: Loading: tokenize\n",
      "2025-04-25 18:32:16 INFO: Loading: mwt\n",
      "2025-04-25 18:32:16 INFO: Loading: pos\n",
      "2025-04-25 18:32:17 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import stanza\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "stanza.download('en')\n",
    "nlp1 = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = stanza.Pipeline(lang='en', processors='tokenize,pos')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b0542",
   "metadata": {},
   "source": [
    "### Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64fa5811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        src = file.read()\n",
    "        src = src.replace(\"\\n\", \" \")\n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45dd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = [[j.lower() for j in word_tokenize(i)] for i in sent_tokenize(text)]\n",
    "\n",
    "    words = []\n",
    "    for sentence in tokens:\n",
    "        words.extend(sentence)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88709f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frequncy_df(words):\n",
    "    text_counts = pd.DataFrame({'word': words})\n",
    "    text_counts = text_counts.groupby('word')['word'].count().reset_index(name='count')\n",
    "    text_counts = text_counts.sort_values(by='count', ascending=False)\n",
    "    text_counts = text_counts[text_counts['word'].str.isalpha()].reset_index(drop=True)\n",
    "    return text_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3d277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(df):\n",
    "    lemma_freq = {}\n",
    "    for _, row in df.iterrows():\n",
    "        word = row['word']\n",
    "        count = row['count']\n",
    "        doc = nlp1(word)\n",
    "        token = doc[0]\n",
    "        if token.like_num:\n",
    "            continue\n",
    "        lemma = token.lemma_\n",
    "        lemma_freq[lemma] = lemma_freq.get(lemma, 0) + count\n",
    "\n",
    "    grouped_df = pd.DataFrame(list(lemma_freq.items()), columns=['word', 'count'])\n",
    "    grouped_df = grouped_df.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b5d8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swl(df, coverage: float = 0.95):\n",
    "    if not 0.0 <= coverage <= 1.0:\n",
    "        raise ValueError(\"`coverage` must be between 0.0 and 1.0\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['cumulative_coverage'] = df['count'].cumsum() / df['count'].sum()\n",
    "    swl = df[df['cumulative_coverage'] <= coverage]\n",
    "    return swl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c51174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    mod_text = (\n",
    "        text[~text['word'].isin(stop_words)]\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return mod_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575bbec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_proper_nouns(df):\n",
    "    drops = []\n",
    "    for i, txt in df['word'].items():\n",
    "        doc = nlp2(txt)\n",
    "        if any(word.upos == 'PROPN' for sent in doc.sentences for word in sent.words):\n",
    "            drops.append(i)\n",
    "    return df.drop(drops).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79fca1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(new_series, original_series):\n",
    "    new_sum = new_series.sum()\n",
    "    original_sum = original_series.sum()\n",
    "    coverage = (new_sum / original_sum) * 100\n",
    "    return print(\"Coverage: \", coverage, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba3757",
   "metadata": {},
   "source": [
    "### Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57adfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_origianl_swl(file_path):\n",
    "    original_df = load_text_file(file_path)\n",
    "    original_df = tokenize_text(original_df)\n",
    "    original_df = generate_frequncy_df(original_df)\n",
    "\n",
    "    return original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "237ef050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmatized_swl(file_path):\n",
    "    # Load the text file\n",
    "    text = load_text_file(file_path)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = tokenize_text(text)\n",
    "\n",
    "    # Generate frequency DataFrame\n",
    "    freq_df = generate_frequncy_df(tokens)\n",
    "\n",
    "    # Lemmatize the words\n",
    "    lemmatized_df = lemmatize(freq_df)\n",
    "    \n",
    "    return lemmatized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c09e4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_95_swl(lemmatized_df, \n",
    "               remove_sw: bool = False, \n",
    "               remove_pn: bool = False):\n",
    "    \n",
    "    # Get the 95% SWL\n",
    "    swl = get_swl(lemmatized_df)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    if remove_sw:\n",
    "        swl = remove_stopwords(swl)\n",
    "\n",
    "    # Remove proper nouns\n",
    "    if remove_pn:\n",
    "        swl = remove_proper_nouns(swl)\n",
    "    \n",
    "    return swl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85bcebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_ngsl_lemmatized(lemmatized_df):\n",
    "    ngsl = pd.read_csv(r\"data/ngsl-v1.2.csv\")\n",
    "    ngsl.rename(columns={'Adjusted Frequency per Million (U)': 'count', 'Lemma': 'word'}, inplace=True)\n",
    "\n",
    "    common_df = pd.merge(\n",
    "    ngsl, lemmatized_df,\n",
    "    on='word',\n",
    "    how='inner',\n",
    "    suffixes=('_ngsl', '_df')\n",
    "    )\n",
    "\n",
    "    coverage = float((common_df['count_df'].sum() / lemmatized_df['count'].sum())* 100)\n",
    "    print(f\"Coverage of NGSL in lemmatized SWL: {coverage:.2f}%\")\n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "960b09a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_nawl_lemmatized(lemmatized_df):\n",
    "    nawl = pd.read_csv(r\"data/NAWL-1.0.csv\")\n",
    "    nawl.rename(columns={'Word': 'word', 'U': 'count'}, inplace=True)\n",
    "\n",
    "    common_df = pd.merge(\n",
    "    nawl, lemmatized_df,\n",
    "    on='word',\n",
    "    how='inner',\n",
    "    suffixes=('_nawl', '_df')\n",
    "    )\n",
    "\n",
    "    coverage = float((common_df['count_df'].sum() / lemmatized_df['count'].sum())* 100)\n",
    "    print(f\"Coverage of NAWL in lemmatized SWL: {coverage:.2f}%\")\n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c817a34",
   "metadata": {},
   "source": [
    "### Text Data Management and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0763c687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6330"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhai_df = load_text_file(r\"data/zhai.txt\")\n",
    "\n",
    "zhai_tokens = tokenize_text(zhai_df)\n",
    "\n",
    "zhai_tokens = generate_frequncy_df(zhai_tokens)\n",
    "\n",
    "len(zhai_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96f03546",
   "metadata": {},
   "outputs": [],
   "source": [
    "zhai_df = get_lemmatized_swl(r\"data/zhai.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0524fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4621\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>10526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be</td>\n",
       "      <td>6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>4873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>4836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>4643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>we</td>\n",
       "      <td>3695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count\n",
       "0   the  10526\n",
       "1    be   6202\n",
       "2    of   4873\n",
       "3     a   4836\n",
       "4    to   4643\n",
       "5    in   4059\n",
       "6    we   3695\n",
       "7   and   3020\n",
       "8  that   2007\n",
       "9  this   1827"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(zhai_df))\n",
    "zhai_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e38cf8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zhai_swl = get_95_swl(zhai_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "689e0952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>cumulative_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>10526</td>\n",
       "      <td>0.060444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be</td>\n",
       "      <td>6202</td>\n",
       "      <td>0.096058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>4873</td>\n",
       "      <td>0.124041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>4836</td>\n",
       "      <td>0.151811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>4643</td>\n",
       "      <td>0.178473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>4059</td>\n",
       "      <td>0.201781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>we</td>\n",
       "      <td>3695</td>\n",
       "      <td>0.222999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>3020</td>\n",
       "      <td>0.240341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.251866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>1827</td>\n",
       "      <td>0.262358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count  cumulative_coverage\n",
       "0   the  10526             0.060444\n",
       "1    be   6202             0.096058\n",
       "2    of   4873             0.124041\n",
       "3     a   4836             0.151811\n",
       "4    to   4643             0.178473\n",
       "5    in   4059             0.201781\n",
       "6    we   3695             0.222999\n",
       "7   and   3020             0.240341\n",
       "8  that   2007             0.251866\n",
       "9  this   1827             0.262358"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(zhai_swl))\n",
    "zhai_swl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b58335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zhai_swl_no_sw = get_95_swl(zhai_df, remove_sw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "102c8ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1322\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>cumulative_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word</td>\n",
       "      <td>1629</td>\n",
       "      <td>0.281727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text</td>\n",
       "      <td>1621</td>\n",
       "      <td>0.291035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>document</td>\n",
       "      <td>1388</td>\n",
       "      <td>0.316221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model</td>\n",
       "      <td>1289</td>\n",
       "      <td>0.331232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datum</td>\n",
       "      <td>1179</td>\n",
       "      <td>0.338002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>topic</td>\n",
       "      <td>1045</td>\n",
       "      <td>0.344003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p</td>\n",
       "      <td>1017</td>\n",
       "      <td>0.355769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>use</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.361586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>would</td>\n",
       "      <td>740</td>\n",
       "      <td>0.381007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>probability</td>\n",
       "      <td>695</td>\n",
       "      <td>0.384997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  count  cumulative_coverage\n",
       "0         word   1629             0.281727\n",
       "1         text   1621             0.291035\n",
       "2     document   1388             0.316221\n",
       "3        model   1289             0.331232\n",
       "4        datum   1179             0.338002\n",
       "5        topic   1045             0.344003\n",
       "6            p   1017             0.355769\n",
       "7          use   1013             0.361586\n",
       "8        would    740             0.381007\n",
       "9  probability    695             0.384997"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(zhai_swl_no_sw))\n",
    "zhai_swl_no_sw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0f4f65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage of NGSL in lemmatized SWL: 80.13%\n"
     ]
    }
   ],
   "source": [
    "zhai_nawl_coverage = compare_ngsl_lemmatized(zhai_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba9a876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage:  94.99781789783168 %\n"
     ]
    }
   ],
   "source": [
    "zhai_swl_coverage = coverage(zhai_swl['count'], zhai_df['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fab872",
   "metadata": {},
   "source": [
    "### Alice in Wonderland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "480cce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1432"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_df = load_text_file(r\"data/alice.txt\")\n",
    "\n",
    "alice_tokens = tokenize_text(alice_df)\n",
    "\n",
    "alice_tokens = generate_frequncy_df(alice_tokens)\n",
    "\n",
    "len(alice_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65d4ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_df = get_lemmatized_swl(r\"data/alice.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "963daee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alice</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  count\n",
       "0    the    634\n",
       "1    she    350\n",
       "2    and    337\n",
       "3     be    309\n",
       "4      a    277\n",
       "5     to    249\n",
       "6      I    201\n",
       "7     of    200\n",
       "8     it    186\n",
       "9  alice    170"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(alice_df))\n",
    "alice_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee8de98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_swl = get_95_swl(alice_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "349498a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>cumulative_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>634</td>\n",
       "      <td>0.066892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she</td>\n",
       "      <td>350</td>\n",
       "      <td>0.103819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>337</td>\n",
       "      <td>0.139375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be</td>\n",
       "      <td>309</td>\n",
       "      <td>0.171977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>277</td>\n",
       "      <td>0.201203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>249</td>\n",
       "      <td>0.227474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I</td>\n",
       "      <td>201</td>\n",
       "      <td>0.248681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>200</td>\n",
       "      <td>0.269783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it</td>\n",
       "      <td>186</td>\n",
       "      <td>0.289407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alice</td>\n",
       "      <td>170</td>\n",
       "      <td>0.307343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  count  cumulative_coverage\n",
       "0    the    634             0.066892\n",
       "1    she    350             0.103819\n",
       "2    and    337             0.139375\n",
       "3     be    309             0.171977\n",
       "4      a    277             0.201203\n",
       "5     to    249             0.227474\n",
       "6      I    201             0.248681\n",
       "7     of    200             0.269783\n",
       "8     it    186             0.289407\n",
       "9  alice    170             0.307343"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(alice_swl))\n",
    "alice_swl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bb9af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_swl_no_sw = get_95_swl(alice_df, remove_sw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d35dd47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>cumulative_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>201</td>\n",
       "      <td>0.248681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alice</td>\n",
       "      <td>170</td>\n",
       "      <td>0.307343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say</td>\n",
       "      <td>160</td>\n",
       "      <td>0.341422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go</td>\n",
       "      <td>66</td>\n",
       "      <td>0.421186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little</td>\n",
       "      <td>58</td>\n",
       "      <td>0.440494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>come</td>\n",
       "      <td>45</td>\n",
       "      <td>0.471407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>get</td>\n",
       "      <td>43</td>\n",
       "      <td>0.475944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>think</td>\n",
       "      <td>40</td>\n",
       "      <td>0.488711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>find</td>\n",
       "      <td>37</td>\n",
       "      <td>0.512872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>like</td>\n",
       "      <td>36</td>\n",
       "      <td>0.516670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  count  cumulative_coverage\n",
       "0       I    201             0.248681\n",
       "1   alice    170             0.307343\n",
       "2     say    160             0.341422\n",
       "3      go     66             0.421186\n",
       "4  little     58             0.440494\n",
       "5    come     45             0.471407\n",
       "6     get     43             0.475944\n",
       "7   think     40             0.488711\n",
       "8    find     37             0.512872\n",
       "9    like     36             0.516670"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(alice_swl_no_sw))\n",
    "alice_swl_no_sw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8aa8ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage of NGSL in lemmatized SWL: 88.75%\n"
     ]
    }
   ],
   "source": [
    "alice_ngsl_coverage = compare_ngsl_lemmatized(alice_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2945b130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage:  94.98839417598649 %\n"
     ]
    }
   ],
   "source": [
    "alice_swl_coverage = coverage(alice_swl['count'], alice_df['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e677088",
   "metadata": {},
   "source": [
    "### Titanic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "236abd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5341\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>3013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rose</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jack</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count\n",
       "0   the   3013\n",
       "1   and   1146\n",
       "2    to   1102\n",
       "3     a   1049\n",
       "4    of    840\n",
       "5    in    665\n",
       "6  rose    664\n",
       "7    is    602\n",
       "8    it    556\n",
       "9  jack    529"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = load_text_file(r\"data/titanic.txt\")\n",
    "titanic_df = tokenize_text(titanic_df)\n",
    "titanic_df = generate_frequncy_df(titanic_df)\n",
    "print(len(titanic_df))\n",
    "titanic_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eee83497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3080\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>cumulative_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rose</td>\n",
       "      <td>664</td>\n",
       "      <td>0.198400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jack</td>\n",
       "      <td>529</td>\n",
       "      <td>0.237874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cal</td>\n",
       "      <td>227</td>\n",
       "      <td>0.344619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cut</td>\n",
       "      <td>200</td>\n",
       "      <td>0.354400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>water</td>\n",
       "      <td>183</td>\n",
       "      <td>0.372090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deck</td>\n",
       "      <td>182</td>\n",
       "      <td>0.376348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>like</td>\n",
       "      <td>179</td>\n",
       "      <td>0.384749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>back</td>\n",
       "      <td>163</td>\n",
       "      <td>0.409060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>boat</td>\n",
       "      <td>140</td>\n",
       "      <td>0.418911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ship</td>\n",
       "      <td>127</td>\n",
       "      <td>0.421883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  count  cumulative_coverage\n",
       "0   rose    664             0.198400\n",
       "1   jack    529             0.237874\n",
       "2    cal    227             0.344619\n",
       "3    cut    200             0.354400\n",
       "4  water    183             0.372090\n",
       "5   deck    182             0.376348\n",
       "6   like    179             0.384749\n",
       "7   back    163             0.409060\n",
       "8   boat    140             0.418911\n",
       "9   ship    127             0.421883"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = get_95_swl(titanic_df, remove_sw=True)\n",
    "print(len(titanic_df))\n",
    "titanic_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f7a3134",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_lemmatized_df = get_lemmatized_swl(r\"data/titanic.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b66ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4050\n",
      "   word  count\n",
      "0   the   3013\n",
      "1   and   1146\n",
      "2    to   1102\n",
      "3    be   1099\n",
      "4     a   1049\n",
      "5   she    899\n",
      "6    of    840\n",
      "7  rise    683\n",
      "8    in    665\n",
      "9    he    592\n"
     ]
    }
   ],
   "source": [
    "print(len(titanic_lemmatized_df))\n",
    "print(titanic_lemmatized_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "926bbad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_swl = get_95_swl(titanic_lemmatized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcf629d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2049\n",
      "   word  count  cumulative_coverage\n",
      "0   the   3013             0.071261\n",
      "1   and   1146             0.098366\n",
      "2    to   1102             0.124429\n",
      "3    be   1099             0.150422\n",
      "4     a   1049             0.175232\n",
      "5   she    899             0.196495\n",
      "6    of    840             0.216362\n",
      "7  rise    683             0.232516\n",
      "8    in    665             0.248244\n",
      "9    he    592             0.262245\n"
     ]
    }
   ],
   "source": [
    "print(len(titanic_swl))\n",
    "print(titanic_swl.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ec1a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_swl_nosw = get_95_swl(titanic_lemmatized_df, remove_sw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f214da16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1948\n",
      "   word  count  cumulative_coverage\n",
      "0  rise    683             0.232516\n",
      "1  jack    529             0.287907\n",
      "2     I    519             0.300182\n",
      "3    go    232             0.376954\n",
      "4   cal    227             0.382323\n",
      "5   cut    211             0.397720\n",
      "6   see    205             0.402569\n",
      "7  deck    192             0.411793\n",
      "8  look    187             0.420662\n",
      "9  boat    184             0.425014\n"
     ]
    }
   ],
   "source": [
    "print(len(titanic_swl_nosw))\n",
    "print(titanic_swl_nosw.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f9fade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage of NGSL in lemmatized SWL: 79.36%\n"
     ]
    }
   ],
   "source": [
    "titanic_ngsl_coverage = compare_ngsl_lemmatized(titanic_lemmatized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0baa500d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage:  94.9977531278825 %\n"
     ]
    }
   ],
   "source": [
    "titanic_swl_coverage = coverage(titanic_swl['count'], titanic_lemmatized_df['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b244578",
   "metadata": {},
   "source": [
    "### Lord of the Rings Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "151ef0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lotr_lemmatized_df = get_lemmatized_swl(r\"data/Lord of the Rings - Chapter One.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a2e4389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394\n",
      "   word  count\n",
      "0   the    496\n",
      "1   and    379\n",
      "2    be    378\n",
      "3    of    287\n",
      "4    he    224\n",
      "5     I    210\n",
      "6    to    201\n",
      "7     a    167\n",
      "8  have    158\n",
      "9   you    154\n"
     ]
    }
   ],
   "source": [
    "print(len(lotr_lemmatized_df))\n",
    "print(lotr_lemmatized_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aeb7b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lotr_swl = get_95_swl(lotr_lemmatized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bd009e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944\n",
      "   word  count  cumulative_coverage\n",
      "0   the    496             0.055129\n",
      "1   and    379             0.097255\n",
      "2    be    378             0.139269\n",
      "3    of    287             0.171168\n",
      "4    he    224             0.196065\n",
      "5     I    210             0.219406\n",
      "6    to    201             0.241747\n",
      "7     a    167             0.260309\n",
      "8  have    158             0.277870\n",
      "9   you    154             0.294987\n"
     ]
    }
   ],
   "source": [
    "print(len(lotr_swl))\n",
    "print(lotr_swl.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2bee95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lotr_swl_nosw = get_95_swl(lotr_lemmatized_df, remove_sw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01e86b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835\n",
      "      word  count  cumulative_coverage\n",
      "0        I    210             0.219406\n",
      "1      say     94             0.368901\n",
      "2    frodo     92             0.379126\n",
      "3     come     42             0.445148\n",
      "4      see     38             0.453929\n",
      "5  gandalf     36             0.462043\n",
      "6    bilbo     36             0.466044\n",
      "7    think     36             0.470046\n",
      "8     many     34             0.477604\n",
      "9     look     33             0.481272\n"
     ]
    }
   ],
   "source": [
    "print(len(lotr_swl_nosw))\n",
    "print(lotr_swl_nosw.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b09cc190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage of NGSL in lemmatized SWL: 83.83%\n"
     ]
    }
   ],
   "source": [
    "lotr_compare_ngsl_coverage = compare_ngsl_lemmatized(lotr_lemmatized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2287ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage:  94.99833277759254 %\n"
     ]
    }
   ],
   "source": [
    "lotr_swl_coverage = coverage(lotr_swl['count'], lotr_lemmatized_df['count'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
